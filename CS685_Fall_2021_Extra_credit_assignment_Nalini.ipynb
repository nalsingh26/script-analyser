{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgNZTjrhcHa0"
      },
      "source": [
        "## Extra credit assignment, CS685 Fall 2021\n",
        "\n",
        "### This is due on December 16, 2021, submitted via Gradescope as a PDF (File>Print>Save as PDF). 100 points total, must be completed in full. It will provide up to 2% on top of your final course grade.\n",
        "\n",
        "#### IMPORTANT: After copying this notebook to your Google Drive, please paste a link to it below. To get a publicly-accessible link, hit the *Share* button at the top right, then click \"Get shareable link\" and copy over the result. If you fail to do this, you will receive no credit for this homework!\n",
        "***LINK: https://colab.research.google.com/drive/1DjOwp7sGtLS07cRLVuQPyjWY2AYFoeZu?usp=sharing\n",
        "\n",
        "---\n",
        "\n",
        "##### *How to do this problem set:*\n",
        "\n",
        "- Some questions require writing Python code and computing results, and the rest of them have written answers. For coding problems, you will have to fill out all code blocks that say `YOUR CODE HERE`.\n",
        "\n",
        "- For text-based answers, you should replace the text that says \"Write your answer here...\" with your actual answer.\n",
        " \n",
        "- This assignment is designed such that each cell takes a few minutes (if that) to run. If it is taking longer than that, you might have made a mistake in your code.\n",
        "\n",
        "---\n",
        "\n",
        "##### *How to submit this problem set:*\n",
        "- Write all the answers in this Colab notebook. Once you are finished, generate a PDF via (File -> Print -> Save as PDF) and upload it to Gradescope.\n",
        "  \n",
        "- **Important:** check your PDF before you submit to Gradescope to make sure it exported correctly. If Colab gets confused about your syntax, it will sometimes terminate the PDF creation routine early.\n",
        "\n",
        "- **Important:** on Gradescope, please make sure that you tag each page with the corresponding question(s). This makes it significantly easier for our graders to grade submissions, especially with the long outputs of many of these cells. We will take off points for submissions that are not tagged.\n",
        "\n",
        "- When creating your final version of the PDF to hand in, please do a fresh restart and execute every cell in order. One handy way to do this is by clicking `Runtime -> Run All` in the notebook menu.\n",
        "\n",
        "---\n",
        "\n",
        "##### *Academic honesty*\n",
        "\n",
        "- We will audit the Colab notebooks from a set number of students, chosen at random. The audits will check that the code you wrote actually generates the answers in your PDF. If you turn in correct answers on your PDF without code that actually generates those answers, we will consider this a serious case of cheating. See the course page for honesty policies.\n",
        "\n",
        "- We will also run automatic checks of Colab notebooks for plagiarism. Copying code from others is also considered a serious case of cheating.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d23zfO_ALKeB"
      },
      "source": [
        "# Part 0: Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N25dvF4jvYoy"
      },
      "source": [
        "## Adding a hardware accelerator\n",
        "The purpose of this homework is to get you acquainted with using large-scale pretrained language models specifically in the context of transfer learning. Since we will be training large neural networks we will attach a GPU, otherwise training will take a very long time.\n",
        "\n",
        "Please go to the menu and add a GPU as follows:\n",
        "\n",
        "`Edit > Notebook Settings > Hardware accelerator > (GPU)`\n",
        "\n",
        "Run the following cell to confirm that the GPU is detected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edOh9ooiIW1B",
        "outputId": "d819ff8b-9b71-45bd-af0a-78845132f463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found device: Tesla P100-PCIE-16GB, n_gpu: 1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Confirm that the GPU is detected\n",
        "\n",
        "assert torch.cuda.is_available()\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = torch.cuda.get_device_name()\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrvH7xx9LnMC"
      },
      "source": [
        "## Installing Hugging Face's Transformers library\n",
        "We will use Hugging Face's Transformers (https://github.com/huggingface/transformers), an open-source library that provides general-purpose architectures for natural language understanding and generation with a collection of various pretrained models made by the NLP community. This library will allow us to easily use pretrained models like `BERT` and perform experiments on top of them. We can use these models to solve downstream target tasks, such as text classification, question answering, and sequence labeling.\n",
        "\n",
        "Run the following cell to install Hugging Face's Transformers library, download data and supporting code for the homework, and install some additional packages. Note that you will be asked to link with your Google Drive account to download some of these files. If you're concerned about security risks (there have not been any issues in previous semesters), feel free to make a new Google account and use it for this homework!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtqS2e5fxpqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f184cf-560f-4573-a581-4c88abee8100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3.4.0\n",
            "  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 27.5 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 18.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 81 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 102 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 112 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 122 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 133 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 143 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 163 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 174 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 184 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 194 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 204 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 215 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 225 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 235 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 245 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 256 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 266 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 276 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 286 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 296 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 307 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 317 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 327 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 337 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 348 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 358 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 368 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 378 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 389 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 399 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 409 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 419 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 430 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 440 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 450 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 460 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 471 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 481 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 491 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 501 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 512 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 522 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 532 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 542 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 552 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 563 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 573 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 583 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 593 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 604 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 614 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 624 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 634 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 645 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 655 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 665 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 675 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 686 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 696 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 706 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 716 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 727 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 737 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 747 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 757 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 768 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 778 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 788 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 798 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 808 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 819 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 829 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 839 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 849 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 860 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 870 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 880 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 890 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 901 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 911 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 921 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 931 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 942 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 952 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 962 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 972 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 983 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 993 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.0 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.0 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.0 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.0 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (3.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (4.62.3)\n",
            "Collecting tokenizers==0.9.2\n",
            "  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 78.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (3.4.0)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 66.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 63.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0) (3.0.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.4.0) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0) (1.1.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.9.2 transformers-3.4.0\n",
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting hstspreload\n",
            "  Downloading hstspreload-2021.12.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 20.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2021.10.8)\n",
            "Collecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16367 sha256=09bafe013ce3b7288ad2674c28cd73a9cf954fecd749180dde0e5126c8411a28\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/be/fe/93a6a40ffe386e16089e44dad9018ebab9dc4cb9eb7eab65ae\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hyperframe, hpack, sniffio, h2, h11, rfc3986, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2021.12.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n",
            "success!\n",
            "Data and supporting code downloaded!\n",
            "model directory created\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting conllu\n",
            "  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (3.1.0a0)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 10.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.7/dist-packages (from googletrans->-r requirements.txt (line 3)) (0.13.3)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (2021.12.1)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (1.5.0)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (0.9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (2021.10.8)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (3.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect->-r requirements.txt (line 4)) (1.15.0)\n",
            "Building wheels for collected packages: seqeval, langdetect\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=721255eeb25eb74499bece6a8894b6c8b2d6eaf7b153e2b4746361ea26817441\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=ea35dcb92acb2d54458f68cfe720600fc8127a0d4cef531a711f08a677175ee3\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "Successfully built seqeval langdetect\n",
            "Installing collected packages: seqeval, langdetect, conllu\n",
            "Successfully installed conllu-4.4.1 langdetect-1.0.9 seqeval-1.2.2\n",
            "everything set up!\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==3.4.0\n",
        "!pip install googletrans==3.1.0a0\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "print('success!')\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "data_file = drive.CreateFile({'id': '1zeo8FcaNUnhN660mGMNEAPvxOE4DPOnE'})\n",
        "data_file.GetContentFile('hw1.zip')\n",
        "\n",
        "# Extract data from the zipfile and put it into the current directory\n",
        "with zipfile.ZipFile('hw1.zip', 'r') as zip_file:\n",
        "    zip_file.extractall('./')\n",
        "os.remove('hw1.zip')\n",
        "# We will use hw1 as our working directory\n",
        "os.chdir('hw1')\n",
        "print(\"Data and supporting code downloaded!\")\n",
        "\n",
        "pretrained_models_dir = './pretrained_models_dir'\n",
        "if not os.path.isdir(pretrained_models_dir):\n",
        "  os.mkdir(pretrained_models_dir)   # directory to save pretrained models\n",
        "print('model directory created')\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "print('everything set up!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1P3h3MWpvlQ"
      },
      "source": [
        "# Part 1. Masked Language Modeling (15 points)\n",
        "\n",
        "In this part, we will use large-scale pretrained language models (e.g., `BERT, XLNet, T5`) for different applications, including masked word completion, text generation, machine translation, and finally for solving downstream target tasks across several classes of problems, i.e., text classification, question answering, and sequence labeling. Let's begin!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FuXH0tOL4pX"
      },
      "source": [
        "We'll use `BERT` [(Devlin et al., 2019)](https://arxiv.org/pdf/1810.04805.pdf) for the task of masked word completion: given an input sentence with some words masked out, predict the masked word(s) based on its context. Run the following cell to download the pretrained `BERT` base model (cased) and tell PyTorch to use the GPU to run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203,
          "referenced_widgets": [
            "03fd0f50f6a248d5866cd28ab855ccb1",
            "99540568054046e1b974682e4d83132d",
            "46f27ea44c2d4e658953b516aa2c5570",
            "356ac7c279f64ed3a3bda5b6e33b0fd4",
            "489892ceabfc40d1b1a8a666bd92c845",
            "fde2f360c4444165ac493fbf62f05104",
            "7b217f2c0bf34849b5d01de8272eeefd",
            "99fd0eb9d4c04bed991b8d7bc5fa6665",
            "e10c03f2293e41a489edd64f14561532",
            "56ff232aa8414bc3a9eec5a862802fd5",
            "a8203f8e7a624e7193c9bd9b65df000f",
            "20b4f132421d4f2c84aecb06ad21cd85",
            "e8728e835bc4419abe1d0dbc9881c23e",
            "e5085e3d63ab443a9fdf39c105268f5d",
            "4977fdf620f640dcbe94fdd9054729d6",
            "dd403224f5fe4350b6718a2cd48d7cec",
            "847a1734180e43b39e1891c035a2eac7",
            "2a5749b541004ea09c7a5212373bb4d9",
            "55a84f7205af4814abcb55c70ddf9d37",
            "597c6a43cfd14053bfdcb26f60737912",
            "e8012872917144e284fdc4135257113d",
            "efe7a0c1cee542c69510e984460786ea",
            "42972fe9e61945419b2872afbd7c77f1",
            "c27247aa26a841639c38c9467f0a9dac",
            "a3c13c5bf34f42768ebb214e1bf5470d",
            "c1942c0fa18944ce82287b333bf4e83c",
            "620b8c418d4d417fbf03e28428c30694",
            "dbe76ef29f3d48faab041b7979022781",
            "e214979a15ad40429441198ae1a6d42d",
            "2c86049a8c924001abab2a3629aae62c",
            "d09ef5106a0a40b786a203274fa105d8",
            "f442026b56af46a78a135293da2cafd6",
            "3871ecd93dd34457829d9eec7bfc03f0"
          ]
        },
        "id": "t1eTyp3EP_JS",
        "outputId": "44a05dff-c274-45d8-df79-39425cbffb46"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03fd0f50f6a248d5866cd28ab855ccb1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20b4f132421d4f2c84aecb06ad21cd85",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42972fe9e61945419b2872afbd7c77f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "success!\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "model_name_or_path = \"bert-base-cased\"\n",
        "cache_dir = os.path.join(pretrained_models_dir, model_name_or_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, cache_dir=cache_dir)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name_or_path, cache_dir=cache_dir)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print('success!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLNhM3jFdt8C"
      },
      "source": [
        "### Question 1.1 (5 points)\n",
        "The below cell passes a single sentence with a [MASK] token into BERT, and returns the logits (i.e., the unnormalized probabilities) of the token prediction at each position of this sequence. Write some code in this cell that prints out the five most probable words for the masked position from the `token_logits` variable. If you did it right, you'll notice that these words mostly will make sense in the given context. \n",
        "\n",
        "*Hints*\n",
        "\n",
        "*   Use `torch.where` to find the index of a masked token within the input tensor (note that `tokenizer.mask_token_id` gives us the index of the mask token in the vocabulary).\n",
        "*   Use `torch.topk` to get the `k` largest elements of a given tensor along a given dimension.\n",
        "*   Use `tokenizer.decode([token_id])` to convert a single integer `token_id` to a token string.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdrIl949h5oq",
        "outputId": "6f524685-ba3b-4e95-d3be-ce52c16da81f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask hat scarf cap handkerchief\n"
          ]
        }
      ],
      "source": [
        "sentence = f\"\"\"We know it’s hard, but the most effective way to get back to the \n",
        "normal sooner is to wear a {tokenizer.mask_token} over your nose \n",
        "and under your chin in public spaces (indoors and outdoors).\"\"\"\n",
        "\n",
        "# Encode the input sentence and get the model's output\n",
        "input = tokenizer.encode(sentence, return_tensors=\"pt\").to(device)\n",
        "# The model outputs the masked language modeling logits of shape \n",
        "# [batch_size, sequence_length, vocab_size] \n",
        "\n",
        "token_logits = model(input)[0]\n",
        "# YOUR CODE HERE!\n",
        "mask_idx = torch.where(input == tokenizer.mask_token_id, 1,-1)\n",
        "mask_logits = token_logits[mask_idx==1]\n",
        "print(tokenizer.decode(torch.topk(mask_logits[0],5).indices))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpa7yclEt53o"
      },
      "source": [
        "### Question 1.2 (5 points)\n",
        "The below cell contains the same context as before but with an increasing number of contiguous [MASK] tokens (run the cell to print out each context).  For each input, replace each [MASK] token with the most probable token (i.e., the argmax of the probability distribution) as predicted by BERT, and then print out the resulting unmasked string. To be clear, your output should be six strings without any [MASK] tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDqYz6-YycEe",
        "outputId": "9443faee-2f2b-4a2d-8e78-2dde264ec031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input 1: We know it’s hard, but the most effective way to get back to the normal sooner is to wear a [MASK] over your nose and under your chin in public spaces (indoors and outdoors).\n",
            "input 2: We know it’s hard, but the most effective way to get back to the normal sooner is to wear a [MASK] [MASK] your nose and under your chin in public spaces (indoors and outdoors).\n",
            "input 3: We know it’s hard, but the most effective way to get back to the normal sooner is to wear a [MASK] [MASK] [MASK] nose and under your chin in public spaces (indoors and outdoors).\n",
            "input 4: We know it’s hard, but the most effective way to get back to the normal sooner is to wear a [MASK] [MASK] [MASK] [MASK] and under your chin in public spaces (indoors and outdoors).\n",
            "input 5: We know it’s hard, but the most effective way to get back to the normal sooner is to wear a [MASK] [MASK] [MASK] [MASK] [MASK] under your chin in public spaces (indoors and outdoors).\n",
            "input 6: We know it’s hard, but the most effective way to get back to the normal sooner is to wear a [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] your chin in public spaces (indoors and outdoors).\n",
            "\n",
            "input 1 predictions: mask\n",
            "input 2 predictions: mask under\n",
            "input 3 predictions: very - your\n",
            "input 4 predictions: \", up up\n",
            "input 5 predictions: \" \" that and right\n",
            "input 6 predictions: black shirt that and and on\n"
          ]
        }
      ],
      "source": [
        "sentence = f\"\"\"We know it’s hard, but the most effective way to get back to the \n",
        "    normal sooner is to wear a {tokenizer.mask_token} over your nose \n",
        "    and under your chin in public spaces (indoors and outdoors).\"\"\"\n",
        "logit_list = []\n",
        "for idx in range(1,7):\n",
        "    x = sentence.split()\n",
        "    for mask_idx in range(idx):\n",
        "        x[20+mask_idx] = tokenizer.mask_token\n",
        "    x = ' '.join(x)\n",
        "    print('input %d: %s' %(idx, x))\n",
        "    input = tokenizer.encode(x, return_tensors=\"pt\").to(device)\n",
        "    token_logits = model(input)[0]\n",
        "    logit_list.append((input, token_logits))\n",
        "\n",
        "print()\n",
        "# YOUR CODE HERE!\n",
        "for idx in range(0,6):\n",
        "  input,logits = logit_list[idx]\n",
        "  mask_idx = torch.where(input == tokenizer.mask_token_id, 1,-1)\n",
        "  mask_logits = logits[mask_idx==1]\n",
        "  print(\"input {} predictions: {}\".format(idx+1,tokenizer.decode(torch.argmax(mask_logits,dim=1))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H238JUcpyfNR"
      },
      "source": [
        "### Question 1.3 (5 points)\n",
        "What do you notice about your outputs as the size of the masked span increases? Explain why this is happening.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8m7IQArywPL"
      },
      "source": [
        "As the number of continuous masks increase, the predictions are becoming worse as BERT predicts words for each masked token independent of the other. This is why we see repetitions like 'and and' and 'up up'. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez253CdmAMd7"
      },
      "source": [
        "# Part 2: Transfer learning with BERT (35 points)\n",
        "\n",
        "With the advent of methods such as `BERT` [(Devlin et al., 2019)](https://arxiv.org/pdf/1810.04805.pdf), the dominant paradigm for developing NLP models has shifted to transfer learning: first, pretrain a large language model on large amounts of unlabeled data, and then fine-tune the resulting model on the downstream target task. In this section, we will use `BERT` to solve downstream target tasks across several classes of problems, including classification, question answering, and sequence labeling.\n",
        "\n",
        "Run the cell below to import necessary packages and set some things up for fine-tuning `BERT`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kDEdMvq9tCr",
        "outputId": "aa28bec0-41da-42ee-c2ce-76d710c1304b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "setup complete\n"
          ]
        }
      ],
      "source": [
        "# coding=utf-8\n",
        "\n",
        "import dataclasses\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import timeit\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Callable, Dict, List, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelWithLMHead,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoModelForQuestionAnswering,\n",
        "    AutoModelForTokenClassification,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedTokenizer,\n",
        "    EvalPrediction\n",
        ")\n",
        "from transformers import (\n",
        "    GlueDataset,\n",
        "    SquadDataset,\n",
        "    LineByLineTextDataset,\n",
        "    TextDataset,\n",
        "    DataCollatorForLanguageModeling,\n",
        ")\n",
        "from transformers import GlueDataTrainingArguments, SquadDataTrainingArguments\n",
        "from transformers import (\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    glue_compute_metrics,\n",
        "    glue_output_modes,\n",
        "    glue_tasks_num_labels,\n",
        "    set_seed,\n",
        ")\n",
        "from transformers.data.processors.squad import SquadResult\n",
        "from transformers.data.metrics.squad_metrics import (\n",
        "    compute_predictions_logits,\n",
        "    squad_evaluate,\n",
        ")\n",
        "from tasks import NER\n",
        "from utils_ner import Split, TokenClassificationDataset, TokenClassificationTask\n",
        "\n",
        "from transformers import glue_processors\n",
        "from transformers.data.processors.utils import InputExample\n",
        "from langdetect import detect\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ModelArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
        "    \"\"\"\n",
        "    model_type: str = field(\n",
        "        default=\"bert\",\n",
        "        metadata={\"help\": \"Model type, e.g., bert.\"}\n",
        "    )\n",
        "    model_name_or_path: str = field(\n",
        "        default=\"bert\",\n",
        "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models.\"}\n",
        "    )\n",
        "    do_lower_case: Optional[bool] = field(\n",
        "        default=False,\n",
        "        metadata={\"help\": \"Whether you want to do lower case on input before tokenization.\"}\n",
        "    )\n",
        "    model_cache_dir: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Where you want to store the pretrained models downloaded from s3.\"}\n",
        "    )\n",
        "    data_cache_dir: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Where you want to store the cached features for the task.\"}\n",
        "    )\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class NerDataTrainingArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
        "    \"\"\"\n",
        "\n",
        "    data_dir: str = field(\n",
        "        metadata={\"help\": \"The input data dir. Should contain data files for the task.\"}\n",
        "    )\n",
        "    labels: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Path to a file containing all labels for the task.\"},\n",
        "    )\n",
        "    max_seq_length: int = field(\n",
        "        default=128,\n",
        "        metadata={\n",
        "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "            \"than this will be truncated, sequences shorter will be padded.\"\n",
        "        },\n",
        "    )\n",
        "    overwrite_cache: bool = field(\n",
        "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets.\"}\n",
        "    )\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LMDataTrainingArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
        "    \"\"\"\n",
        "\n",
        "    train_data_file: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"The input training data file (a text file).\"}\n",
        "    )\n",
        "    eval_data_file: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"An optional input evaluation data file to evaluate the perplexity on (a text file).\"},\n",
        "    )\n",
        "    line_by_line: bool = field(\n",
        "        default=False,\n",
        "        metadata={\"help\": \"Whether distinct lines of text in the dataset are to be handled as distinct sequences.\"},\n",
        "    )\n",
        "\n",
        "    mlm: bool = field(\n",
        "        default=False, metadata={\"help\": \"Train with masked-language modeling loss instead of language modeling.\"}\n",
        "    )\n",
        "    mlm_probability: float = field(\n",
        "        default=0.15, metadata={\"help\": \"Ratio of tokens to mask for masked language modeling loss\"}\n",
        "    )\n",
        "    block_size: int = field(\n",
        "        default=-1,\n",
        "        metadata={\n",
        "            \"help\": \"Optional input sequence length after tokenization.\"\n",
        "            \"The training dataset will be truncated in block of this size for training.\"\n",
        "            \"Default to the model max input length for single sentence inputs (take into account special tokens).\"\n",
        "        },\n",
        "    )\n",
        "    overwrite_cache: bool = field(\n",
        "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
        "    )\n",
        "\n",
        "\n",
        "def get_dataset(\n",
        "    args: LMDataTrainingArguments,\n",
        "    tokenizer: PreTrainedTokenizer,\n",
        "    evaluate: bool = False,\n",
        "    cache_dir: Optional[str] = None,\n",
        "):\n",
        "    file_path = args.eval_data_file if evaluate else args.train_data_file\n",
        "    if args.line_by_line:\n",
        "        return LineByLineTextDataset(tokenizer=tokenizer, file_path=file_path, block_size=args.block_size)\n",
        "    else:\n",
        "        return TextDataset(\n",
        "            tokenizer=tokenizer,\n",
        "            file_path=file_path,\n",
        "            block_size=args.block_size,\n",
        "            overwrite_cache=args.overwrite_cache,\n",
        "            cache_dir=cache_dir,\n",
        "        )\n",
        "\n",
        "\n",
        "DATA_TRAINING_ARGUMENTS = {\n",
        "    \"text_classification\": GlueDataTrainingArguments,\n",
        "    \"question_answering\": SquadDataTrainingArguments,\n",
        "    \"sequence_labeling\": NerDataTrainingArguments,\n",
        "}\n",
        "\n",
        "\n",
        "AUTO_MODEL = {\n",
        "    \"text_classification\": AutoModelForSequenceClassification,\n",
        "    \"question_answering\": AutoModelForQuestionAnswering,\n",
        "    \"sequence_labeling\": AutoModelForTokenClassification,\n",
        "}\n",
        "\n",
        "\n",
        "DATASET = {\n",
        "    \"text_classification\": GlueDataset,\n",
        "    \"question_answering\": SquadDataset,\n",
        "    \"sequence_labeling\": TokenClassificationDataset,\n",
        "}\n",
        "\n",
        "\n",
        "# some functions for fine-tuning BERT on a downstream target task\n",
        "def do_target_task_finetuning(model_name_or_path, task_type, output_dir, **kwargs):\n",
        "    r\"\"\" Fine-tuning BERT on a downstream target task.\n",
        "    Params:\n",
        "        **model_name_or_path**: either:\n",
        "            - a string with the `shortcut name` of a pre-trained model configuration to load from cache\n",
        "                or download and cache if not already stored in cache (e.g. 'bert-base-uncased').\n",
        "            - a path to a `directory` containing a configuration file saved\n",
        "                using the `save_pretrained(save_directory)` method.\n",
        "            - a path or url to a saved configuration `file`.\n",
        "        **task_type**: string:\n",
        "            The class of the task to train, selected in\n",
        "            [\"text_classification\", \"question_answering\", \"sequence_labeling\"].\n",
        "        **output_dir**: string:\n",
        "            The output directory where the model predictions and checkpoints will be written.\n",
        "        **kwargs**: (`optional`) dict:\n",
        "            Dictionary of key/value pairs with which to update the configuration object after loading.\n",
        "            - The values in kwargs of any keys which are configuration attributes will be used\n",
        "            to override the loaded values.\n",
        "    \"\"\"\n",
        "    # See all possible arguments in src/transformers/training_args.py\n",
        "\n",
        "    assert task_type in DATA_TRAINING_ARGUMENTS\n",
        "    model_args = ModelArguments(model_name_or_path=model_name_or_path)\n",
        "    data_args_params = {}\n",
        "    for param in [\"task_name\", \"data_dir\"]:\n",
        "        if param in kwargs:\n",
        "            data_args_params.update({param: kwargs[param]})\n",
        "\n",
        "    data_args = DATA_TRAINING_ARGUMENTS[task_type](**data_args_params)\n",
        "    training_args = TrainingArguments(output_dir=output_dir)\n",
        "\n",
        "    # override the loaded configs\n",
        "    configs = (model_args, data_args, training_args)\n",
        "    for config in configs:\n",
        "        for key, value in kwargs.items():\n",
        "            if hasattr(config, key):\n",
        "                setattr(config, key, value)\n",
        "\n",
        "    if (\n",
        "        os.path.exists(training_args.output_dir)\n",
        "        and os.listdir(training_args.output_dir)\n",
        "        and training_args.do_train\n",
        "        and not training_args.overwrite_output_dir\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
        "            f\"Use --overwrite_output_dir to overcome.\"\n",
        "        )\n",
        "\n",
        "    for p in [model_args.model_cache_dir, model_args.data_cache_dir, training_args.output_dir]:\n",
        "        if not os.path.exists(p):\n",
        "            os.makedirs(p)\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO,\n",
        "    )\n",
        "\n",
        "    logger.info(\"Process device: %s, n_gpu: %s\", training_args.device, training_args.n_gpu)\n",
        "    logger.info(\"Training/evaluation parameters %s\", training_args)\n",
        "\n",
        "\n",
        "    # Set seed\n",
        "    set_seed(training_args.seed)\n",
        "\n",
        "    if task_type == \"text_classification\":\n",
        "        try:\n",
        "            data_args.task_name = data_args.task_name.lower()\n",
        "            num_labels = glue_tasks_num_labels[data_args.task_name]\n",
        "            output_mode = glue_output_modes[data_args.task_name]\n",
        "        except KeyError:\n",
        "            raise ValueError(\"Task not found: %s\" % (data_args.task_name))\n",
        "    elif task_type == \"sequence_labeling\":\n",
        "        token_classification_task = NER() # You might want to this to Chunk() or POS()\n",
        "        # if you are working with a Chunk or POS task, respectively\n",
        "        labels = token_classification_task.get_labels(data_args.labels)\n",
        "        label_map: Dict[int, str] = {i: label for i, label in enumerate(labels)}\n",
        "        num_labels = len(labels)\n",
        "\n",
        "    # Load pretrained model and tokenizer\n",
        "\n",
        "    AutoModel = AUTO_MODEL[task_type]\n",
        "    auto_config_params = {\n",
        "        'pretrained_model_name_or_path': model_args.model_name_or_path,\n",
        "        'cache_dir': model_args.model_cache_dir,\n",
        "    }\n",
        "\n",
        "    if task_type == \"text_classification\":\n",
        "        auto_config_params.update({\n",
        "            \"num_labels\": num_labels,\n",
        "            \"finetuning_task\": data_args.task_name,\n",
        "        })\n",
        "    elif task_type == \"sequence_labeling\":\n",
        "        auto_config_params.update({\n",
        "            \"num_labels\": num_labels,\n",
        "            \"id2label\": label_map,\n",
        "            \"label2id\": {label: i for i, label in enumerate(labels)},\n",
        "        })\n",
        "\n",
        "    config = AutoConfig.from_pretrained(**auto_config_params)\n",
        "\n",
        "    auto_tokenizer_params = {\n",
        "        \"pretrained_model_name_or_path\": model_args.model_name_or_path,\n",
        "        \"cache_dir\": model_args.model_cache_dir,\n",
        "        \"do_lower_case\": model_args.do_lower_case,\n",
        "    }\n",
        "    tokenizer = AutoTokenizer.from_pretrained(**auto_tokenizer_params)\n",
        "\n",
        "    auto_model_params = {\n",
        "        \"pretrained_model_name_or_path\": model_args.model_name_or_path,\n",
        "        \"from_tf\": False,\n",
        "        \"config\": config,\n",
        "        \"cache_dir\": model_args.model_cache_dir,\n",
        "    }\n",
        "\n",
        "    if \"model_load_mode\" in kwargs and kwargs[\"model_load_mode\"] == \"base_model_only\":\n",
        "        WEIGHTS_NAME = \"pytorch_model.bin\"\n",
        "        archive_file = os.path.join(model_args.model_name_or_path, WEIGHTS_NAME)\n",
        "        # Use torch.load with map_location=torch.device() to map the pretrained model to our device.\n",
        "        model_state_dict = torch.load(archive_file, map_location=torch.device(training_args.device))\n",
        "        \n",
        "        state_dict_with_prefix = {}\n",
        "        for key, value in model_state_dict.items():\n",
        "            if key.startswith(model_args.model_type):\n",
        "                state_dict_with_prefix[key] = value\n",
        "\n",
        "        auto_model_params.update({\"state_dict\": state_dict_with_prefix})\n",
        "        \n",
        "    model = AutoModel.from_pretrained(**auto_model_params)\n",
        "\n",
        "    # Get datasets\n",
        "    Dataset = DATASET[task_type]\n",
        "    dataset_params = {\n",
        "        \"tokenizer\": tokenizer,\n",
        "    }\n",
        "    if task_type == \"sequence_labeling\":\n",
        "        dataset_params.update({\n",
        "            \"token_classification_task\": token_classification_task,\n",
        "            \"data_dir\": data_args.data_dir,\n",
        "            \"labels\": labels,\n",
        "            \"model_type\": model_args.model_type,\n",
        "            \"max_seq_length\": data_args.max_seq_length\n",
        "        })\n",
        "\n",
        "    else:\n",
        "        dataset_params.update({\n",
        "            \"args\": data_args,\n",
        "            \"cache_dir\": model_args.data_cache_dir,\n",
        "        })\n",
        "\n",
        "    train_dataset = (Dataset(**dataset_params) if training_args.do_train else None)\n",
        "\n",
        "    dataset_params.update({\"mode\": Split.dev if task_type == \"sequence_labeling\" else \"dev\"})\n",
        "    eval_dataset = (Dataset(**dataset_params) if training_args.do_eval else None)\n",
        "\n",
        "    # Initialize our Trainer\n",
        "    trainer_params = {\n",
        "        \"model\": model,\n",
        "        \"args\": training_args,\n",
        "        \"train_dataset\": train_dataset,\n",
        "        \"eval_dataset\": eval_dataset,\n",
        "    }\n",
        "    trainer = Trainer(**trainer_params)\n",
        "\n",
        "    # Training\n",
        "    if training_args.do_train:\n",
        "        trainer.train(\n",
        "            model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\n",
        "        )\n",
        "        trainer.save_model()\n",
        "        # For convenience, we also re-save the tokenizer to the same directory\n",
        "        tokenizer.save_pretrained(training_args.output_dir)\n",
        "\n",
        "    # Evaluation\n",
        "    eval_results = {}\n",
        "    if training_args.do_eval:\n",
        "        if task_type == \"text_classification\":\n",
        "            def build_compute_metrics_fn(task_name: str) -> Callable[[EvalPrediction], Dict]:\n",
        "                def compute_metrics_fn(p: EvalPrediction):\n",
        "                    if output_mode == \"classification\":\n",
        "                        preds = np.argmax(p.predictions, axis=1)\n",
        "                    elif output_mode == \"regression\":\n",
        "                        preds = np.squeeze(p.predictions)\n",
        "                    return glue_compute_metrics(task_name, preds, p.label_ids)\n",
        "                return compute_metrics_fn\n",
        "\n",
        "            logger.info(\"*** Evaluate ***\")\n",
        "            # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "            eval_datasets = [eval_dataset]\n",
        "            if data_args.task_name == \"mnli\":\n",
        "                mnli_mm_data_args = dataclasses.replace(data_args, task_name=\"mnli-mm\")\n",
        "                eval_datasets.append(\n",
        "                    Dataset(mnli_mm_data_args, tokenizer=tokenizer, mode=\"dev\", cache_dir=model_args.data_cache_dir)\n",
        "                )\n",
        "\n",
        "            for eval_dataset in eval_datasets:\n",
        "                trainer.compute_metrics = build_compute_metrics_fn(eval_dataset.args.task_name)\n",
        "                eval_result = trainer.evaluate(eval_dataset=eval_dataset)\n",
        "\n",
        "                output_eval_file = os.path.join(training_args.output_dir, f\"eval_results.txt\")\n",
        "                with open(output_eval_file, \"w\") as writer:\n",
        "                    logger.info(\"***** Eval results *****\")\n",
        "                    for key, value in eval_result.items():\n",
        "                        logger.info(\"  %s = %s\", key, value)\n",
        "                        writer.write(\"%s = %s\\n\" % (key, value))\n",
        "\n",
        "                eval_results.update(eval_result)\n",
        "\n",
        "        elif task_type == \"question_answering\":\n",
        "            # We don't use trainer.evaluate here since it currently does not support question answering tasks\n",
        "            # (https://github.com/huggingface/transformers/issues/7032)\n",
        "            model = AutoModel.from_pretrained(model_args.model_cache_dir)\n",
        "            tokenizer = AutoTokenizer.from_pretrained(model_args.model_cache_dir, do_lower_case=model_args.do_lower_case)\n",
        "            model.to(training_args.device)\n",
        "\n",
        "\n",
        "            dataset = eval_dataset.dataset\n",
        "            examples = eval_dataset.examples\n",
        "            features = eval_dataset.features\n",
        "            eval_batch_size = training_args.per_gpu_eval_batch_size * max(1, training_args.n_gpu)\n",
        "\n",
        "            eval_sampler = SequentialSampler(dataset)\n",
        "            eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=eval_batch_size)\n",
        "\n",
        "            logger.info(\"*** Evaluate ***\")\n",
        "            description = \"Evaluation\"\n",
        "            logger.info(\"***** Running %s *****\", description)\n",
        "            logger.info(\"  Num examples = %d\", len(dataset))\n",
        "            logger.info(\"  Batch size = %d\", eval_batch_size)\n",
        "\n",
        "            all_results = []\n",
        "            start_time = timeit.default_timer()\n",
        "\n",
        "            for batch in tqdm(eval_dataloader, desc=description):\n",
        "                model.eval()\n",
        "                batch = tuple(t.to(training_args.device) for t in batch)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    inputs = {\n",
        "                        \"input_ids\": batch[0],\n",
        "                        \"attention_mask\": batch[1],\n",
        "                        \"token_type_ids\": batch[2],\n",
        "                    }\n",
        "                    feature_indices = batch[3]\n",
        "                    outputs = model(**inputs)\n",
        "\n",
        "                for i, feature_index in enumerate(feature_indices):\n",
        "                    eval_feature = features[feature_index.item()]\n",
        "                    unique_id = int(eval_feature.unique_id)\n",
        "                    output = [output[i].detach().cpu().tolist() for output in outputs]\n",
        "                    start_logits, end_logits = output\n",
        "                    result = SquadResult(unique_id, start_logits, end_logits)\n",
        "                    all_results.append(result)\n",
        "\n",
        "            evalTime = timeit.default_timer() - start_time\n",
        "            logger.info(\"  Evaluation done in total %f secs (%f sec per example)\", evalTime, evalTime / len(dataset))\n",
        "\n",
        "            # Compute predictions\n",
        "            output_prediction_file = os.path.join(training_args.output_dir, \"predictions.json\")\n",
        "            output_nbest_file = os.path.join(training_args.output_dir, \"nbest_predictions.json\")\n",
        "\n",
        "            output_null_log_odds_file = os.path.join(training_args.output_dir, \"null_odds.json\") \\\n",
        "                if data_args.version_2_with_negative else None\n",
        "\n",
        "            predictions = compute_predictions_logits(\n",
        "                all_examples=examples,\n",
        "                all_features=features,\n",
        "                all_results=all_results,\n",
        "                n_best_size=data_args.n_best_size,\n",
        "                max_answer_length=data_args.max_answer_length,\n",
        "                do_lower_case=model_args.do_lower_case,\n",
        "                output_prediction_file=output_prediction_file,\n",
        "                output_nbest_file=output_nbest_file,\n",
        "                output_null_log_odds_file=output_null_log_odds_file,\n",
        "                verbose_logging=False,\n",
        "                version_2_with_negative=data_args.version_2_with_negative,\n",
        "                null_score_diff_threshold=data_args.null_score_diff_threshold,\n",
        "                tokenizer=tokenizer,\n",
        "            )\n",
        "\n",
        "            # Compute the F1 and exact scores.\n",
        "            eval_result = squad_evaluate(examples, predictions)\n",
        "\n",
        "            output_eval_file = os.path.join(training_args.output_dir, f\"eval_results.txt\")\n",
        "            with open(output_eval_file, \"w\") as writer:\n",
        "                logger.info(\"***** Eval results *****\")\n",
        "                for key, value in eval_result.items():\n",
        "                    logger.info(\"  %s = %s\", key, value)\n",
        "                    writer.write(\"%s = %s\\n\" % (key, value))\n",
        "\n",
        "            eval_results.update(eval_result)\n",
        "\n",
        "\n",
        "        elif task_type == \"sequence_labeling\":\n",
        "            def align_predictions(predictions: np.ndarray, label_ids: np.ndarray) -> Tuple[List[int], List[int]]:\n",
        "                preds = np.argmax(predictions, axis=2)\n",
        "                batch_size, seq_len = preds.shape\n",
        "                label_list = [[] for _ in range(batch_size)]\n",
        "                pred_list = [[] for _ in range(batch_size)]\n",
        "\n",
        "                for i in range(batch_size):\n",
        "                    for j in range(seq_len):\n",
        "                        if label_ids[i, j] != torch.nn.CrossEntropyLoss().ignore_index:\n",
        "                            label_list[i].append(label_map[label_ids[i][j]])\n",
        "                            pred_list[i].append(label_map[preds[i][j]])\n",
        "                return pred_list, label_list\n",
        "\n",
        "            def compute_metrics_fn(p: EvalPrediction) -> Dict:\n",
        "                pred_list, label_list = align_predictions(p.predictions, p.label_ids)\n",
        "                return {\n",
        "                    \"accuracy_score\": accuracy_score(label_list, pred_list),\n",
        "                    \"precision\": precision_score(label_list, pred_list),\n",
        "                    \"recall\": recall_score(label_list, pred_list),\n",
        "                    \"f1\": f1_score(label_list, pred_list),\n",
        "                }\n",
        "\n",
        "            trainer.compute_metrics = compute_metrics_fn\n",
        "            eval_result = trainer.evaluate(eval_dataset=eval_dataset)\n",
        "\n",
        "            output_eval_file = os.path.join(training_args.output_dir, f\"eval_results.txt\")\n",
        "            with open(output_eval_file, \"w\") as writer:\n",
        "                logger.info(\"***** Eval results *****\")\n",
        "                for key, value in eval_result.items():\n",
        "                    logger.info(\"  %s = %s\", key, value)\n",
        "                    writer.write(\"%s = %s\\n\" % (key, value))\n",
        "\n",
        "            eval_results.update(eval_result)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid task type.\")\n",
        "    return eval_results\n",
        "\n",
        "\n",
        "print('setup complete')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfWAtDLLx8SK"
      },
      "source": [
        "## Fine-tuning BERT for text classification\n",
        "Now, let's use `BERT` to solve a sentiment classification task. Specifically, we'll be using the Stanford Sentiment Treebank [(Socher et al., 2013)](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf), which was constructed from movie reviews data. We provide code to fine-tune BERT in a separate [\"useful code\" Colab notebook](https://colab.research.google.com/drive/1nJWA9rPkPrjjjtwN_vKUSQoomdfWLAFV?usp=sharing), so check that out if you're interested. However, since training on the full `SST` dataset (67K examples) takes a while, we provide you with a fine-tuned model to save time. Run the following cell to download the model. \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFI0mKwUYk58",
        "outputId": "8a795b2d-603b-485d-9826-3d074b481710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert-base-cased-finetuned-sst downloaded!\n"
          ]
        }
      ],
      "source": [
        "data_file = drive.CreateFile({'id': '1ZJ1_gWahH_OOBIrRm0aN9i8nvLB2olZC'})\n",
        "data_file.GetContentFile('bert-base-cased-finetuned-sst.zip')\n",
        "\n",
        "# Extract the data from the zipfile and put it into pretrained_models_dir\n",
        "with zipfile.ZipFile('bert-base-cased-finetuned-sst.zip', 'r') as zip_file:\n",
        "    zip_file.extractall(pretrained_models_dir)\n",
        "os.remove('bert-base-cased-finetuned-sst.zip')\n",
        "print(\"bert-base-cased-finetuned-sst downloaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6In7sN0P_cs"
      },
      "source": [
        "Run the cell below to evaluate the trained model on the dev set. You should get an accuracy around 92%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "d5YvAzA5QJER",
        "outputId": "e7149ba0-f546-4185-c9a3-eed9554cf581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/11/2021 21:40:14 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/11/2021 21:40:14 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/finetuning/smallSST', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec11_21-40-14_94c7f39254b5', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/finetuning/smallSST', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/11/2021 21:40:17 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/11/2021 21:40:21 - INFO - __main__ -   ***** Eval results *****\n",
            "12/11/2021 21:40:21 - INFO - __main__ -     eval_loss = 0.2701866924762726\n",
            "12/11/2021 21:40:21 - INFO - __main__ -     eval_acc = 0.9197247706422018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time elapsed: 7.216126300000269 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "task_name = \"SST\"\n",
        "data_dir = f\"./data/small{task_name}\"\n",
        "model_name_or_path = \"bert-base-cased-finetuned-sst\"\n",
        "model_cache_dir = os.path.join(pretrained_models_dir, model_name_or_path)\n",
        "data_cache_dir = f\"./data_cache/finetuning/small{task_name}\"\n",
        "output_dir = f\"./output/finetuning/small{task_name}\"\n",
        "\n",
        "do_target_task_finetuning(\n",
        "    model_name_or_path=model_cache_dir,\n",
        "    task_name=f\"{task_name}-2\",\n",
        "    task_type=\"text_classification\",\n",
        "    do_train=False,\n",
        "    do_eval=True, \n",
        "    do_lower_case=True,\n",
        "    data_dir=data_dir,\n",
        "    max_seq_length=128,\n",
        "    model_cache_dir=model_cache_dir,\n",
        "    data_cache_dir=data_cache_dir,\n",
        "    output_dir=output_dir,\n",
        "\n",
        ")\n",
        "elapsed_time = timeit.default_timer() - start_time\n",
        "print(f\"Time elapsed: {elapsed_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMugs2KHRUZN"
      },
      "source": [
        "### Question 2.1 (5 points)\n",
        "Let's use the trained model to predict the sentiment of a given sentence. We will make a few predictions in the code below. Your task is to complete the code to print out the model's predicted probability distribution for each sentence.\n",
        "\n",
        "*Hint:*\n",
        "\n",
        "*   `model(inputs)[0]` gives you the logits of the model for `inputs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlaiLg-a5f8Y",
        "outputId": "986980da-73b3-424d-8cf7-8c98aa85a407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0395, 0.9736], grad_fn=<SigmoidBackward0>)\n",
            "tensor([0.9397, 0.0328], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Load the trained model and make a few predictions\n",
        "model_name_or_path = \"bert-base-cased-finetuned-sst\"\n",
        "pretrained_weights = os.path.join(pretrained_models_dir, model_name_or_path)\n",
        "task_type = \"text_classification\"\n",
        "model = AUTO_MODEL[task_type].from_pretrained(pretrained_weights)\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_weights)\n",
        "\n",
        "classes = [\"negative\", \"positive\"]\n",
        "\n",
        "sentence_1 = \"the movie has something interesting to say\"\n",
        "sentence_2 = \"it was so awful that i walked out after 30 minutes :(\"\n",
        "\n",
        "inputs_1 = tokenizer.encode(sentence_1, add_special_tokens=True, return_tensors=\"pt\")\n",
        "inputs_2 = tokenizer.encode(sentence_2, add_special_tokens=True, return_tensors=\"pt\")\n",
        "\n",
        "print(torch.sigmoid(model(inputs_1)[0][0]))\n",
        "print(torch.sigmoid(model(inputs_2)[0][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLdj1V1yZnSO"
      },
      "source": [
        "### Question 2.2 (5 points)\n",
        "Come up with a new sentence that the model gets wrong. The sentence must contain some sentiment (i.e., it cannot be neutral), and the model should place a higher probability on the wrong label than the correct one. Show the model's prediction on this new sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmKYU5zratKI",
        "outputId": "60534528-8821-4e65-b493-b85aeaa147e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your sentence: \"My favorite ice-cream parlor, Sweet Treat, made their final ice-cream batch ever today.\"\n",
            "ground-truth label: Negative\n",
            "predicted negative prob: 0.17\n",
            "predicted positive prob: 0.80\n"
          ]
        }
      ],
      "source": [
        "your_sentence = 'My favorite ice-cream parlor, Sweet Treat, made their final ice-cream batch ever today.' \n",
        "your_sentence_sentiment = 'Negative' # change to your sentence's ground-truth sentiment\n",
        "\n",
        "# YOUR CODE HERE\n",
        "encoded_sentence = tokenizer.encode(your_sentence, add_special_tokens=True, return_tensors=\"pt\")\n",
        "your_model_prediction = torch.sigmoid(model(encoded_sentence)[0][0])\n",
        "print('your sentence: \"%s\"\\nground-truth label: %s\\npredicted negative prob: %0.2f\\npredicted positive prob: %0.2f'\\\n",
        "      % (your_sentence, your_sentence_sentiment, your_model_prediction[0], your_model_prediction[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTdT62X1cSfg"
      },
      "source": [
        "### Question 2.3 (5 points)\n",
        "Provide a reasonable explanation as to why the model got your sentence wrong. Also provide a plausible method to improve the underlying sentiment model so that this kind of error stops happening."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sosXqVsIfAOc"
      },
      "source": [
        "### Answer:\n",
        "The sentence implies that the ice-cream store is going to close but it has words like 'Sweet','Treat' that is skewing the sentiment to the positive side. The model can be trained on more such sentences where the sentiments are not very obvious to make it robust against these kinds of sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt4_JfmX7w5d"
      },
      "source": [
        "## Fine-tuning BERT for question answering\n",
        "In this section, we will use `BERT` for a question answering task, i.e., `SQuAD` [(Rajpurkar et al., 2016)](https://nlp.stanford.edu/pubs/rajpurkar2016squad.pdf) whose dataset was built from Wikipedia. Training on the full `SQuAD` dataset (108K examples) would takes a couple of hours, so we will provide you with a trained model to save your time. Run the following cell to download the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMhmA6i61Cqt",
        "outputId": "5e8a8f9a-ae6a-4cff-c3db-1ef781f584bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert-base-cased-finetuned-squad downloaded!\n"
          ]
        }
      ],
      "source": [
        "data_file = drive.CreateFile({'id': '19cnGSN88KlRJRcIqwxw3C4ylJftdkZ2W'})\n",
        "data_file.GetContentFile('bert-base-cased-finetuned-squad.zip')\n",
        "\n",
        "# Extract the data from the zipfile and put it into pretrained_models_dir\n",
        "with zipfile.ZipFile('bert-base-cased-finetuned-squad.zip', 'r') as zip_file:\n",
        "    zip_file.extractall(pretrained_models_dir)\n",
        "os.remove('bert-base-cased-finetuned-squad.zip')\n",
        "print(\"bert-base-cased-finetuned-squad downloaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CkbeUxR5fNw"
      },
      "source": [
        "### Question 2.4 (10 points)\n",
        "\n",
        "Okay, same drill as before! Your task is to complete the code to show the model's predicted answer to each question. If you forgot how `BERT` solves extractive question answering tasks, check out Section 4.2 and Figure 1 / Figure 4c) in the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf). Your output should be three strings, each corresponding to the answer of one of the three given questions. \n",
        "\n",
        "*Hints*\n",
        "\n",
        "*   `model(**inputs)]` gives you the start and end logits of the model for  `inputs`.\n",
        "*   Use `tokenizer.convert_tokens_to_string` to convert a sequence of tokens (string) into a single string.\n",
        "*   Use `tokenizer.convert_ids_to_tokens` to convert a sequence of indices into a sequence of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5COVCSw6f5h",
        "outputId": "6846f6a3-5249-4f30-d30a-91e0d28e400e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the focus of this course?\n",
            "deep learning methods for natural language processing\n",
            "\n",
            "Who is this course intended for?\n",
            "graduate students in computer science and linguistics\n",
            "\n",
            "What is the coursework?\n",
            "reading recent research papers , programming assignments , and a final project\n",
            "\n"
          ]
        }
      ],
      "source": [
        "task_name = \"SQuAD\"\n",
        "model_name_or_path = \"bert-base-cased-finetuned-squad\"\n",
        "pretrained_weights = os.path.join(pretrained_models_dir, model_name_or_path)\n",
        "task_type = \"question_answering\"\n",
        "model = AUTO_MODEL[task_type].from_pretrained(pretrained_weights)\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_weights)\n",
        "\n",
        "context = \"\"\"This course will broadly focus on deep learning methods for \n",
        "natural language processing. Most of the semester will focus on very recent \n",
        "transfer learning methods that have significantly pushed forward the state of \n",
        "the art. It is intended for graduate students in computer science and \n",
        "linguistics who are (1) interested in learning about cutting-edge research \n",
        "progress in NLP and (2) familiar with machine learning fundamentals. We will \n",
        "cover modeling architectures, training objectives, and downstream tasks (e.g., \n",
        "text classification, question answering, and text generation). Coursework \n",
        "includes reading recent research papers, programming assignments, and a final \n",
        "project. This class will be asynchronous: lectures will be prerecorded and \n",
        "posted on a weekly basis, along with accompanying readings and assignments.\"\"\"\n",
        "\n",
        "questions = [\n",
        "    \"What is the focus of this course?\",\n",
        "    \"Who is this course intended for?\",\n",
        "    \"What is the coursework?\",\n",
        "]\n",
        "# YOUR CODE HERE!\n",
        "def get_answer(inputs):\n",
        "  output = model(**inputs)\n",
        "  start = torch.argmax(output[0].squeeze())\n",
        "  end = torch.argmax(output[1].squeeze())\n",
        "  answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[start:end+1]))\n",
        "  return answer\n",
        "\n",
        "for question in questions:\n",
        "    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "    # YOUR CODE HERE!\n",
        "    print(question)\n",
        "    print(get_answer(inputs))\n",
        "    print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjPQa9bGhNKL"
      },
      "source": [
        "### Question 2.5 (5 points)\n",
        "Come up with a new question about this passage that the model gets wrong. The question must be answerable by the passage (i.e., its ground-truth answer should be a span of text within the passage). Show the model's predicted answer on this new sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJJeSHlZhfgH",
        "outputId": "d2ef28c4-5bdc-4773-eeb1-3d017bd610da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your question: \"Can graduate students take this course?\"\n",
            "ground-truth answer: It is intended for graduate students in computer science and linguistics\n",
            "predicted answer: [CLS]\n"
          ]
        }
      ],
      "source": [
        "your_question = 'Can graduate students take this course?'\n",
        "your_answer = 'It is intended for graduate students in computer science and linguistics'\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "inputs = tokenizer.encode_plus(your_question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
        "input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "\n",
        "your_model_prediction = get_answer(inputs)\n",
        "print('your question: \"%s\"\\nground-truth answer: %s\\npredicted answer: %s'\\\n",
        "      % (your_question, your_answer, your_model_prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyS1OJ6sh70y"
      },
      "source": [
        "### Question 2.6 (5 points)\n",
        "Provide a reasonable explanation as to why the model got your question wrong. Also provide a plausible method to improve the underlying QA model so that this kind of error stops happening."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb24NVS_h70z"
      },
      "source": [
        "### Answer:\n",
        "On experimenting with a few questions, I found that this model is not able to answer yes or no type of questions.\n",
        "\n",
        "This can resolved by adding these types of questions in the training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUkBOfjuqKYn"
      },
      "source": [
        "# Part 3: Low-resource NLP (50 points)\n",
        "\n",
        "In this second part of the homework, we will experiment with an extremely low-resource setting for which there are only a few training examples available for the downstream target task. We provide you with a tiny version of the `SST` dataset called `tinySST` (located at `data/tinySST`) with only 20 training examples (10 examples per each class). We will explore various data augmentation and finetuning approaches to improve the target task performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lap7BetPiWhX"
      },
      "source": [
        "`BERT` is unstable and prone to\n",
        "degenerate performance on tasks with small training sets. The below cell fine-tunes `BERT` on `tinySST` using some default hyperparameters and also reports the mean and standard deviation of the dev set accuracy across 4 random seeds. Run the cell to obtain these baseline numbers, which should be around 50% average accuracy  (it might take a couple of minutes to finish)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BI-0LhpWP-UL",
        "outputId": "cab880c5-fbab-4b2b-9c1b-cb8b1c5b3620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:53:08 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:53:08 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-1234', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=2e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-53-08_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=1234, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-1234', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:53:14 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:53:14 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-2341', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=2e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-53-14_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=2341, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-2341', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:53:19 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:53:19 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-3412', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=2e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-53-19_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=3412, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-3412', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:53:24 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:53:24 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-4123', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=2e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-53-24_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=4123, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-4123', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:53:30 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:53:30 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-1234', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-53-30_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=1234, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-1234', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/14/2021 15:53:33 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:53:37 - INFO - __main__ -   ***** Eval results *****\n",
            "12/14/2021 15:53:37 - INFO - __main__ -     eval_loss = 0.709531843662262\n",
            "12/14/2021 15:53:37 - INFO - __main__ -     eval_acc = 0.4908256880733945\n",
            "12/14/2021 15:53:37 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:53:37 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-2341', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-53-37_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=2341, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-2341', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/14/2021 15:53:39 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:53:43 - INFO - __main__ -   ***** Eval results *****\n",
            "12/14/2021 15:53:43 - INFO - __main__ -     eval_loss = 0.6759335994720459\n",
            "12/14/2021 15:53:43 - INFO - __main__ -     eval_acc = 0.6387614678899083\n",
            "12/14/2021 15:53:43 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:53:43 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-3412', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-53-43_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=3412, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-3412', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/14/2021 15:53:45 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:53:49 - INFO - __main__ -   ***** Eval results *****\n",
            "12/14/2021 15:53:49 - INFO - __main__ -     eval_loss = 0.7309039831161499\n",
            "12/14/2021 15:53:49 - INFO - __main__ -     eval_acc = 0.5091743119266054\n",
            "12/14/2021 15:53:49 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:53:49 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-4123', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-53-49_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=4123, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-4123', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/14/2021 15:53:52 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:53:56 - INFO - __main__ -   ***** Eval results *****\n",
            "12/14/2021 15:53:56 - INFO - __main__ -     eval_loss = 0.7028253078460693\n",
            "12/14/2021 15:53:56 - INFO - __main__ -     eval_acc = 0.3967889908256881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on TinySST dev set: 0.5088876146788991 +/- 0.08625490508613544\n",
            "Time elapsed: 47.73050501300003 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "task_name = \"SST\"\n",
        "data_dir = f\"./data/tiny{task_name}\"\n",
        "model_name_or_path = \"bert-base-cased\"\n",
        "model_cache_dir = os.path.join(pretrained_models_dir, model_name_or_path)\n",
        "data_cache_dir = f\"./data_cache/finetuning/tiny{task_name}\"\n",
        "\n",
        "# Fine-tune BERT with default hyperparameters using 4 random seeds\n",
        "for seed in [1234, 2341, 3412, 4123]:\n",
        "  output_dir = f\"./output/tiny{task_name}-{seed}\"\n",
        "  do_target_task_finetuning(\n",
        "      seed=seed,\n",
        "      model_name_or_path=model_name_or_path,\n",
        "      task_name=f\"{task_name}-2\",\n",
        "      task_type=\"text_classification\",\n",
        "      do_train=True,\n",
        "      do_eval=False, \n",
        "      do_lower_case=True,\n",
        "      data_dir=data_dir,\n",
        "      max_seq_length=128,\n",
        "      per_device_train_batch_size=32,\n",
        "      learning_rate=2e-5,\n",
        "      num_train_epochs=3,\n",
        "      model_cache_dir=model_cache_dir,\n",
        "      data_cache_dir=data_cache_dir,\n",
        "      output_dir=output_dir,\n",
        "      overwrite_output_dir=True\n",
        "  )\n",
        "\n",
        "# Evaluate BERT on the dev set\n",
        "results = []\n",
        "for seed in [1234, 2341, 3412, 4123]:\n",
        "  model_dir = f\"./output/tiny{task_name}-{seed}\"\n",
        "  result = do_target_task_finetuning(\n",
        "      seed=seed,\n",
        "      model_name_or_path=model_dir,\n",
        "      task_name=f\"{task_name}-2\",\n",
        "      task_type=\"text_classification\",\n",
        "      do_train=False,\n",
        "      do_eval=True, \n",
        "      do_lower_case=True,\n",
        "      data_dir=data_dir,\n",
        "      max_seq_length=128,\n",
        "      model_cache_dir=model_cache_dir,\n",
        "      data_cache_dir=data_cache_dir,\n",
        "      output_dir=model_dir\n",
        "  )\n",
        "  results.append(result[\"eval_acc\"])\n",
        "\n",
        "results = np.array(results)\n",
        "mean = np.mean(results)\n",
        "std = np.std(results)\n",
        "\n",
        "print(f\"Accuracy on TinySST dev set: {mean} +/- {std}\")\n",
        "elapsed_time = timeit.default_timer() - start_time\n",
        "print(f\"Time elapsed: {elapsed_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osgAYIVflUPy"
      },
      "source": [
        "### Question 3.1 (10 points)\n",
        "These default fine-tuning hyperparameters are not optimal for such a small dataset. Some recent work has proposed simple tweaks to improve training stability and model performance in these settings [(Mosbach et al, 2020](https://arxiv.org/pdf/2006.04884.pdf), [Zhang et al., 2020)](https://arxiv.org/pdf/2006.05987.pdf). After looking through these papers, make some modifications to the arguments of the training command in the below cell (which currently just contains the previous cell's code) that result in a higher mean accuracy and a lower standard deviation than what we observed above. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_wfGYwBlkPTv",
        "outputId": "8bd6d5cc-6bfa-4ca3-c4c4-05859bb2ca8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:53:56 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:53:56 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-1234', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-53-56_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=1234, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-1234', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 00:14, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:54:15 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:54:15 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-2341', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-54-15_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=2341, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-2341', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 00:14, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:54:35 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:54:35 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-3412', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-54-35_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=3412, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-3412', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 00:14, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:54:54 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:54:54 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-4123', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-54-54_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=4123, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-4123', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 00:14, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:55:13 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:55:13 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-1234', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-55-13_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=1234, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-1234', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/14/2021 15:55:15 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:55:19 - INFO - __main__ -   ***** Eval results *****\n",
            "12/14/2021 15:55:19 - INFO - __main__ -     eval_loss = 2.228085517883301\n",
            "12/14/2021 15:55:19 - INFO - __main__ -     eval_acc = 0.606651376146789\n",
            "12/14/2021 15:55:19 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:55:19 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-2341', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-55-19_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=2341, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-2341', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/14/2021 15:55:22 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:55:26 - INFO - __main__ -   ***** Eval results *****\n",
            "12/14/2021 15:55:26 - INFO - __main__ -     eval_loss = 1.1277037858963013\n",
            "12/14/2021 15:55:26 - INFO - __main__ -     eval_acc = 0.783256880733945\n",
            "12/14/2021 15:55:26 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:55:26 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-3412', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-55-26_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=3412, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-3412', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/14/2021 15:55:28 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:55:32 - INFO - __main__ -   ***** Eval results *****\n",
            "12/14/2021 15:55:32 - INFO - __main__ -     eval_loss = 1.71431565284729\n",
            "12/14/2021 15:55:32 - INFO - __main__ -     eval_acc = 0.661697247706422\n",
            "12/14/2021 15:55:32 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:55:32 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-4123', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-55-32_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=4123, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-4123', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/14/2021 15:55:34 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:55:38 - INFO - __main__ -   ***** Eval results *****\n",
            "12/14/2021 15:55:38 - INFO - __main__ -     eval_loss = 2.361671209335327\n",
            "12/14/2021 15:55:38 - INFO - __main__ -     eval_acc = 0.6318807339449541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on TinySST dev set: 0.6708715596330275 +/- 0.06774796095294462\n",
            "Time elapsed: 102.13805197599999 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "task_name = \"SST\"\n",
        "data_dir = f\"./data/tiny{task_name}\"\n",
        "model_name_or_path = \"bert-base-cased\"\n",
        "model_cache_dir = os.path.join(pretrained_models_dir, model_name_or_path)\n",
        "data_cache_dir = f\"./data_cache/finetuning/tiny{task_name}\"\n",
        "\n",
        "# Fine-tune BERT with your hyperparameters using 4 random seeds\n",
        "for seed in [1234, 2341, 3412, 4123]:\n",
        "  output_dir = f\"./output/tiny{task_name}-{seed}\"\n",
        "\n",
        "  ### CHANGE ONLY THE ARGUMENTS TO THE BELOW FUNCTION\n",
        "  do_target_task_finetuning(\n",
        "      seed=seed,\n",
        "      model_name_or_path=model_name_or_path,\n",
        "      task_name=f\"{task_name}-2\",\n",
        "      task_type=\"text_classification\",\n",
        "      do_train=True,\n",
        "      do_eval=False, \n",
        "      do_lower_case=True,\n",
        "      data_dir=data_dir,\n",
        "      max_seq_length=128,\n",
        "      per_device_train_batch_size=16,\n",
        "      learning_rate=5e-5,\n",
        "      num_train_epochs=50,\n",
        "      model_cache_dir=model_cache_dir,\n",
        "      data_cache_dir=data_cache_dir,\n",
        "      output_dir=output_dir,\n",
        "      overwrite_output_dir=True\n",
        "  )\n",
        "\n",
        "# Evaluate BERT on the dev set\n",
        "results = []\n",
        "for seed in [1234, 2341, 3412, 4123]:\n",
        "  model_dir = f\"./output/tiny{task_name}-{seed}\"\n",
        "  result = do_target_task_finetuning(\n",
        "      seed=seed,\n",
        "      model_name_or_path=model_dir,\n",
        "      task_name=f\"{task_name}-2\",\n",
        "      task_type=\"text_classification\",\n",
        "      do_train=False,\n",
        "      do_eval=True, \n",
        "      do_lower_case=True,\n",
        "      data_dir=data_dir,\n",
        "      max_seq_length=128,\n",
        "      model_cache_dir=model_cache_dir,\n",
        "      data_cache_dir=data_cache_dir,\n",
        "      output_dir=model_dir\n",
        "  )\n",
        "  results.append(result[\"eval_acc\"])\n",
        "\n",
        "results = np.array(results)\n",
        "mean = np.mean(results)\n",
        "std = np.std(results)\n",
        "\n",
        "print(f\"Accuracy on TinySST dev set: {mean} +/- {std}\")\n",
        "elapsed_time = timeit.default_timer() - start_time\n",
        "print(f\"Time elapsed: {elapsed_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D7XfZ30yjSB"
      },
      "source": [
        "### Question 3.2 (5 points)\n",
        "Explain the changes that you made and provide some justification as to why they resulted in an improvement over the default hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho_V4XYhnfE8"
      },
      "source": [
        "**Write your answer here!** Please keep it brief (i.e., 2-3 sentences).\n",
        "\n",
        "Increasing the epochs from 3 to 50 increased the accuracy from 0.508 to 0.61 this is because the model is being trained for longer.\n",
        "\n",
        "Increasing the learning rate from $2e^{-5}$ to $5e^{-5}$ increased the accuracy to 0.637. This indicates that the previous learning rate was low for the model. We can make the learning rate adaptive while training so that the model does not bounce around the minima because of high learning rate.\n",
        "\n",
        "Decreasing the batch size from 32 to 16 further increased the accuracy to 0.67. This indicates that a batch size of 16 is leading to faster convergence to a local minima than batch size of 32."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oyoLZFCgINA"
      },
      "source": [
        "## Intermediate task fine-tuning\n",
        " [Phang et al. (2019)](https://arxiv.org/pdf/1811.01088.pdf) proposed the paradigm of *intermediate-task fine-tuning*: first, fine-tune `BERT` on an intermediate task, and then fine-tune the resulting model on the target task. They showed that using data-rich supervised tasks as intermediate tasks can substantially improve `BERT`'s performance on the target task. However, the conditions for successful intermediate-task fine-tuning (i.e., which tasks make good intermediate tasks) remain unclear. [Pruksachatkun et al. 2020](https://arxiv.org/pdf/2005.00628.pdf) observe that intermediate tasks that require high-level inference and reasoning abilities tend to work best, while [Vu et al. 2020](https://arxiv.org/pdf/2005.00770.pdf) indicate that the similarity between the intermediate task and the target task is crucial for successful intermediate-task fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUTbAhzJkqsz"
      },
      "source": [
        "In this question, we will use intermediate fine-tuning to improve our `tinySST` accuracy by first fine-tuning `BERT` on a data-rich supervised task. Here, we'll consider two tasks: natural language inference via the `MNLI` dataset [(Williams et al., 2018)](https://www.aclweb.org/anthology/N18-1101.pdf), which has 393K training examples, and `Yelp Review Full` [(Zhang et al., 2015)](https://arxiv.org/pdf/1509.01626.pdf), which is a 5-way sentiment classification task that has 650K training examples.\n",
        "\n",
        "Since fine-tuning `BERT` on these datasets takes several hours, we will provide you with trained models to save your time. Run the following cell to download the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3nhZVYsdfOg",
        "outputId": "c487d790-8047-41af-ffc2-fb70771ab86e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert-base-cased-finetuned-mnli downloaded!\n",
            "bert-base-cased-finetuned-yelp downloaded!\n"
          ]
        }
      ],
      "source": [
        "data_file = drive.CreateFile({'id': '1BGJYmTEq7PLmree42MfFsvYdDQPLaNR1'})\n",
        "data_file.GetContentFile('bert-base-cased-finetuned-mnli.zip')\n",
        "\n",
        "# Extract the data from the zipfile and put it into the data directory\n",
        "with zipfile.ZipFile('bert-base-cased-finetuned-mnli.zip', 'r') as zip_file:\n",
        "    zip_file.extractall(pretrained_models_dir)\n",
        "os.remove('bert-base-cased-finetuned-mnli.zip')\n",
        "print(\"bert-base-cased-finetuned-mnli downloaded!\")\n",
        "\n",
        "data_file = drive.CreateFile({'id': '1stDkJtL9xczoHH-iQnQ9GSZTseLILD-b'})\n",
        "data_file.GetContentFile('bert-base-cased-finetuned-yelp.zip')\n",
        "\n",
        "# Extract the data from the zipfile and put it into the data directory\n",
        "with zipfile.ZipFile('bert-base-cased-finetuned-yelp.zip', 'r') as zip_file:\n",
        "    zip_file.extractall(pretrained_models_dir)\n",
        "os.remove('bert-base-cased-finetuned-yelp.zip')\n",
        "print(\"bert-base-cased-finetuned-yelp downloaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFFr5IdOo2YA"
      },
      "source": [
        "### Question 3.3 (10 points)\n",
        "In the cell below, you should write code to fine-tune the `bert-base-cased-finetuned-mnli` model for `tinySST` and then evaluate the resulting model on the `tinySST` dev set. Unlike in previous problems, here we will just do the fine-tuning once (not with multiple random seeds). We don't provide any scaffolding code here, but you should have enough from previous cells to complete this fairly easily. Please use the improved hyperparameters you found in problem 3.1. This cell should print out the `tinySST` dev accuracy.\n",
        "\n",
        "*Hint*\n",
        "*   Since `MNLI` has three classes while `SST` has two, we need to discard its final classification layer. You can do this by calling `do_target_task_finetuning` with the argument `model_load_mode = \"base_model_only\"`. Please look at the cell above that defines the `do_target_task_finetuning` function to understand what this does. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "_CumzlYhvBd1",
        "outputId": "1b41370d-98ff-4cca-91ce-14542bd5643b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:55:58 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:55:58 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-1234', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-55-58_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=1234, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-1234', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./pretrained_models_dir/bert-base-cased-finetuned-mnli and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 00:14, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:56:16 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 15:56:16 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-1234', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_15-56-16_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=1234, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-1234', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/14/2021 15:56:19 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 15:56:23 - INFO - __main__ -   ***** Eval results *****\n",
            "12/14/2021 15:56:23 - INFO - __main__ -     eval_loss = 0.9061482548713684\n",
            "12/14/2021 15:56:23 - INFO - __main__ -     eval_acc = 0.8222477064220184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on TinySST dev set: 0.8222477064220184 +/- 0.0\n",
            "Time elapsed: 24.544652955999993 seconds\n"
          ]
        }
      ],
      "source": [
        "### YOUR CODE HERE\n",
        "start_time = timeit.default_timer()\n",
        "task_name = \"SST\"\n",
        "data_dir = f\"./data/tiny{task_name}\"\n",
        "model_name_or_path = \"bert-base-cased-finetuned-mnli\"\n",
        "model_cache_dir = os.path.join(pretrained_models_dir, model_name_or_path)\n",
        "data_cache_dir = f\"./data_cache/finetuning/tiny{task_name}\"\n",
        "\n",
        "# Fine-tune BERT with your hyperparameters using 4 random seeds\n",
        "for seed in [1234]:\n",
        "  output_dir = f\"./output/tiny{task_name}-{seed}\"\n",
        "\n",
        "  ### CHANGE ONLY THE ARGUMENTS TO THE BELOW FUNCTION\n",
        "  do_target_task_finetuning(\n",
        "      model_load_mode = \"base_model_only\",\n",
        "      seed=seed,\n",
        "      model_name_or_path=model_cache_dir,\n",
        "      task_name=f\"{task_name}-2\",\n",
        "      task_type=\"text_classification\",\n",
        "      do_train=True,\n",
        "      do_eval=False, \n",
        "      do_lower_case=True,\n",
        "      data_dir=data_dir,\n",
        "      max_seq_length=128,\n",
        "      per_device_train_batch_size=16,\n",
        "      learning_rate=5e-5,\n",
        "      num_train_epochs=50,\n",
        "      model_cache_dir=model_cache_dir,\n",
        "      data_cache_dir=data_cache_dir,\n",
        "      output_dir=output_dir,\n",
        "      overwrite_output_dir=True\n",
        "  )\n",
        "\n",
        "# Evaluate BERT on the dev set\n",
        "results = []\n",
        "for seed in [1234]:\n",
        "  model_dir = f\"./output/tiny{task_name}-{seed}\"\n",
        "  result = do_target_task_finetuning(\n",
        "      seed=seed,\n",
        "      model_name_or_path=model_dir,\n",
        "      task_name=f\"{task_name}-2\",\n",
        "      task_type=\"text_classification\",\n",
        "      do_train=False,\n",
        "      do_eval=True, \n",
        "      do_lower_case=True,\n",
        "      data_dir=data_dir,\n",
        "      max_seq_length=128,\n",
        "      model_cache_dir=model_cache_dir,\n",
        "      data_cache_dir=data_cache_dir,\n",
        "      output_dir=model_dir\n",
        "  )\n",
        "  results.append(result[\"eval_acc\"])\n",
        "\n",
        "results = np.array(results)\n",
        "mean = np.mean(results)\n",
        "std = np.std(results)\n",
        "\n",
        "print(f\"Accuracy on TinySST dev set: {mean} +/- {std}\")\n",
        "elapsed_time = timeit.default_timer() - start_time\n",
        "print(f\"Time elapsed: {elapsed_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNcOi9_FQ8Sz"
      },
      "source": [
        "In the below cell, do the same thing as you did in the previous cell, except fine-tune the `bert-base-cased-finetuned-yelp` model instead of the MNLI model. This cell should again print the `tinySST` dev accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "cGi2LU7dRF-y",
        "outputId": "248d95f7-20ac-40c5-ce6e-6c7649fb583a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/11/2021 21:49:03 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/11/2021 21:49:03 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-1234', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec11_21-49-03_94c7f39254b5', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=1234, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-1234', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./pretrained_models_dir/bert-base-cased-finetuned-yelp and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 00:14, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/11/2021 21:49:22 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/11/2021 21:49:22 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-1234', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec11_21-49-22_94c7f39254b5', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=1234, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-1234', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/11/2021 21:49:25 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/11/2021 21:49:29 - INFO - __main__ -   ***** Eval results *****\n",
            "12/11/2021 21:49:29 - INFO - __main__ -     eval_loss = 1.0754761695861816\n",
            "12/11/2021 21:49:29 - INFO - __main__ -     eval_acc = 0.7717889908256881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on TinySST dev set: 0.7717889908256881 +/- 0.0\n",
            "Time elapsed: 25.91485637400001 seconds\n"
          ]
        }
      ],
      "source": [
        "### YOUR CODE HERE\n",
        "start_time = timeit.default_timer()\n",
        "task_name = \"SST\"\n",
        "data_dir = f\"./data/tiny{task_name}\"\n",
        "model_name_or_path = \"bert-base-cased-finetuned-yelp\"\n",
        "model_cache_dir = os.path.join(pretrained_models_dir, model_name_or_path)\n",
        "data_cache_dir = f\"./data_cache/finetuning/tiny{task_name}\"\n",
        "\n",
        "# Fine-tune BERT with your hyperparameters using 4 random seeds\n",
        "for seed in [1234]:\n",
        "  output_dir = f\"./output/tiny{task_name}-{seed}\"\n",
        "\n",
        "  ### CHANGE ONLY THE ARGUMENTS TO THE BELOW FUNCTION\n",
        "  do_target_task_finetuning(\n",
        "      model_load_mode = \"base_model_only\",\n",
        "      seed=seed,\n",
        "      model_name_or_path=model_cache_dir,\n",
        "      task_name=f\"{task_name}-2\",\n",
        "      task_type=\"text_classification\",\n",
        "      do_train=True,\n",
        "      do_eval=False, \n",
        "      do_lower_case=True,\n",
        "      data_dir=data_dir,\n",
        "      max_seq_length=128,\n",
        "      per_device_train_batch_size=16,\n",
        "      learning_rate=5e-5,\n",
        "      num_train_epochs=50,\n",
        "      model_cache_dir=model_cache_dir,\n",
        "      data_cache_dir=data_cache_dir,\n",
        "      output_dir=output_dir,\n",
        "      overwrite_output_dir=True\n",
        "  )\n",
        "\n",
        "# Evaluate BERT on the dev set\n",
        "results = []\n",
        "for seed in [1234]:\n",
        "  model_dir = f\"./output/tiny{task_name}-{seed}\"\n",
        "  result = do_target_task_finetuning(\n",
        "      seed=seed,\n",
        "      model_name_or_path=model_dir,\n",
        "      task_name=f\"{task_name}-2\",\n",
        "      task_type=\"text_classification\",\n",
        "      do_train=False,\n",
        "      do_eval=True, \n",
        "      do_lower_case=True,\n",
        "      data_dir=data_dir,\n",
        "      max_seq_length=128,\n",
        "      model_cache_dir=model_cache_dir,\n",
        "      data_cache_dir=data_cache_dir,\n",
        "      output_dir=model_dir\n",
        "  )\n",
        "  results.append(result[\"eval_acc\"])\n",
        "\n",
        "results = np.array(results)\n",
        "mean = np.mean(results)\n",
        "std = np.std(results)\n",
        "\n",
        "print(f\"Accuracy on TinySST dev set: {mean} +/- {std}\")\n",
        "elapsed_time = timeit.default_timer() - start_time\n",
        "print(f\"Time elapsed: {elapsed_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFRAMdaHv8PY"
      },
      "source": [
        "### Question 3.4 (5 points)\n",
        "Compare your results to the mean result you got in problem 3.1 without any intermediate fine-tuning. What was your best model, and why do you think it outperformed the others? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN6T9LOAynyG"
      },
      "source": [
        "### Answer:\n",
        "\n",
        "The model trained on MNLI performed best. This could be because of the diversity of the type of textual data present in MNLI(10 diverse genres) when compared to Yelp Review.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOoa0-V0wVMG"
      },
      "source": [
        "## Data augmentation using back-translation\n",
        "In this part, we will explore another approach to improve `BERT`'s performance on the target task: creating more training data (*data augmentation*) using *backtranslation*. Backtranslation refers to the process of translating a sentence from language `X` into another language `Y` (called the *pivot language*) and then translating the resulting sentence back into language `X`. Often, the final sentence contains significant lexical and syntactic variation compared to the original sentence, while roughly preserving its meaning. Here, we will use backtranslation to  obtain paraphrases of the training data of the `tinySST` dataset.\n",
        "\n",
        "Run the following cell to load Google Translate's model and run it on a toy example."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans"
      ],
      "metadata": {
        "id": "SZkPXQfYmOVm",
        "outputId": "379cddbd-4331-472f-d32c-77b3743a02d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.7/dist-packages (3.1.0a0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.7/dist-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (2021.12.1)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (2021.10.8)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (1.2.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sjVa8OfzfhJj",
        "outputId": "3c393ef3-99b4-4f47-ab1f-a8448545ee2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"J'aime le traitement du langage naturel\""
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import googletrans\n",
        "# Run print(googletrans.LANGUAGES) to see available languages\n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "\n",
        "# translate from English to French\n",
        "output = translator.translate(\"I love natural language processing\", src='en', dest='fr')\n",
        "output.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abWjM7tEhwXA"
      },
      "source": [
        "### Question 3.5 (15 points)\n",
        "Complete the following cell to paraphrase the training data of `tinySST` using backtranslation. We have intentionally left this problem open-ended: feel free to use as many pivot languages as you like, and also write any postprocessing code you think might help. The cell after this one will fine-tune BERT on the augmented training data, so you can use its output to validate your backtranslation strategy. To obtain full points, the model fine-tuned on your augmented data must achieve a higher average accuracy than the model without any augmentation, trained with the same hyperparameters. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv9uXRaWwVrT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b9edccf-51d3-47b4-883c-257afebd7614"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./data/tinySST-bt/dev.tsv'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "task_name = \"SST\"\n",
        "data_dir = f\"./data/tiny{task_name}\"\n",
        "task_processor = glue_processors[f\"{task_name.lower()}-2\"]()\n",
        "train_examples = task_processor.get_train_examples(data_dir)\n",
        "\n",
        "train_examples_augmented = []\n",
        "\n",
        "### (incomplete) list of languages you can use\n",
        "languages = [\n",
        "    'en', # english\n",
        "    'cs',  # czech\n",
        "    'de',  # german\n",
        "    'es', # spanish\n",
        "    'fi',  # finnish\n",
        "    'fr', # french\n",
        "    'hi', # hindi\n",
        "    'it', # italian\n",
        "    'ja', # japanese\n",
        "    'pt', # portuguese\n",
        "    'ru', # russian\n",
        "    'vi', # vietnamese\n",
        "    'zh-cn',  # chinese\n",
        "    ]\n",
        "\n",
        "# generate some augmented examples for each training example\n",
        "for example in train_examples:\n",
        "    train_examples_augmented.append(example) # always include the original example\n",
        "\n",
        "    # YOUR CODE HERE!\n",
        "    # the below line adds a single new augmented example to the dataset. \n",
        "    # note that the guid should be a unique ID for this example, so you'll want to vary this\n",
        "    # depending on how you generate your paraphrases\n",
        "    \n",
        "    #print(example.text_a)\n",
        "    input = example.text_a\n",
        "    # 1 pivot language\n",
        "    for lang in languages:\n",
        "      pivot = translator.translate(input, src='en', dest=lang)\n",
        "      aug_eng = translator.translate(pivot.text, src=lang,dest='en')\n",
        "      train_examples_augmented.append(InputExample(guid=f\"{example.guid}-aug-{lang}\",\n",
        "                                                    text_a=input,\n",
        "                                                    text_b=aug_eng.text,\n",
        "                                                    label=example.label))\n",
        "    \n",
        "    # 2 pivot languages\n",
        "    for i in range(len(languages)-1):\n",
        "      pivot1 = translator.translate(input, src='en', dest=languages[i])\n",
        "      pivot2 = translator.translate(pivot1.text, src=languages[i], dest=languages[i+1])\n",
        "      aug_eng = translator.translate(pivot2.text, src=languages[i+1],dest='en')\n",
        "      train_examples_augmented.append(InputExample(guid=f\"{example.guid}-aug-{lang}\",\n",
        "                                                    text_a=input,\n",
        "                                                    text_b=aug_eng.text,\n",
        "                                                    label=example.label))\n",
        "    # 3 pivot languages\n",
        "    for i in range(len(languages)-2):\n",
        "      pivot1 = translator.translate(input, src='en', dest=languages[i])\n",
        "      pivot2 = translator.translate(pivot1.text, src=languages[i], dest=languages[i+1])\n",
        "      pivot3 = translator.translate(pivot2.text, src=languages[i+1],dest=languages[i+2])\n",
        "      aug_eng = translator.translate(pivot3.text, src=languages[i+2],dest='en')\n",
        "      train_examples_augmented.append(InputExample(guid=f\"{example.guid}-aug-{lang}\",\n",
        "                                                    text_a=input,\n",
        "                                                    text_b=aug_eng.text,\n",
        "                                                    label=example.label))\n",
        "\n",
        "output_dir = f\"./data/tiny{task_name}-bt\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "    \n",
        "with open(os.path.join(output_dir, \"train.tsv\"), \"w\") as writer:\n",
        "    writer.write(\"sentence\\tlabel\\n\")\n",
        "    for example in train_examples_augmented:\n",
        "        writer.write(f\"{example.text_a}\\t{example.label}\\n\")\n",
        "\n",
        "# Copy the original tinySST's dev set to the new directory\n",
        "import shutil\n",
        "shutil.copyfile(f\"{data_dir}/dev.tsv\", f\"{output_dir}/dev.tsv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axEnQx7tk2U-"
      },
      "source": [
        "The below cell fine-tunes BERT `bert-base-cased` with the combined training data (real + synthetic training examples) and then evaluates the resulting model on tinySST's dev set. Note that it uses the default fine-tuning hyperparameters, not the improved ones that you found earlier. You should observe a significantly higher accuracy than 50% when you run this cell on the augmented data (our reference implementation reaches 64%). ***Do NOT modify any code in this cell!***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IzC7JT7muYw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed24b001-cdc1-4644-f2f8-4c3caa6dce6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 16:08:24 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 16:08:24 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-bt-1234', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=2e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_16-08-24_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=1234, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-bt-1234', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [72/72 00:26, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 16:08:56 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 16:08:56 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-bt-2341', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=2e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_16-08-56_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=2341, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-bt-2341', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [72/72 00:26, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 16:09:28 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 16:09:28 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-bt-3412', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=2e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_16-09-28_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=3412, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-bt-3412', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [72/72 00:26, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 16:10:00 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 16:10:00 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-bt-4123', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=2e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_16-10-00_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=4123, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-bt-4123', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [72/72 00:26, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 16:10:31 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 16:10:31 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-bt-1234', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_16-10-31_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=1234, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-bt-1234', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/14/2021 16:10:34 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 16:10:38 - INFO - __main__ -   ***** Eval results *****\n",
            "12/14/2021 16:10:38 - INFO - __main__ -     eval_loss = 1.2293007373809814\n",
            "12/14/2021 16:10:38 - INFO - __main__ -     eval_acc = 0.6089449541284404\n",
            "12/14/2021 16:10:38 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 16:10:38 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-bt-2341', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_16-10-38_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=2341, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-bt-2341', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/14/2021 16:10:41 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 16:10:45 - INFO - __main__ -   ***** Eval results *****\n",
            "12/14/2021 16:10:45 - INFO - __main__ -     eval_loss = 0.6933794021606445\n",
            "12/14/2021 16:10:45 - INFO - __main__ -     eval_acc = 0.7190366972477065\n",
            "12/14/2021 16:10:45 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 16:10:45 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-bt-3412', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_16-10-45_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=3412, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-bt-3412', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/14/2021 16:10:47 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 16:10:51 - INFO - __main__ -   ***** Eval results *****\n",
            "12/14/2021 16:10:51 - INFO - __main__ -     eval_loss = 0.8218250870704651\n",
            "12/14/2021 16:10:51 - INFO - __main__ -     eval_acc = 0.6123853211009175\n",
            "12/14/2021 16:10:51 - INFO - __main__ -   Process device: cuda:0, n_gpu: 1\n",
            "12/14/2021 16:10:51 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./output/tinySST-bt-4123', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec14_16-10-51_342ddffec148', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=4123, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./output/tinySST-bt-4123', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "12/14/2021 16:10:54 - INFO - __main__ -   *** Evaluate ***\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12/14/2021 16:10:57 - INFO - __main__ -   ***** Eval results *****\n",
            "12/14/2021 16:10:57 - INFO - __main__ -     eval_loss = 1.2098560333251953\n",
            "12/14/2021 16:10:57 - INFO - __main__ -     eval_acc = 0.6009174311926605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Data augmentation using back-translation =====\n",
            "Performance when fine-tuning BERT: 0.6353211009174312 +/- 0.04851202086774651\n",
            "Time elapsed: 153.79493235500013 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "task_name = \"SST\"\n",
        "data_dir = f\"./data/tiny{task_name}-bt\"\n",
        "model_name_or_path = \"bert-base-cased\"\n",
        "model_cache_dir = os.path.join(pretrained_models_dir, model_name_or_path)\n",
        "data_cache_dir = f\"./data_cache/finetuning/tiny{task_name}-bt/\"\n",
        "output_dir = model_cache_dir\n",
        "\n",
        "mean = None\n",
        "std = None\n",
        "\n",
        "# Fine-tune BERT using 4 random seeds\n",
        "for seed in [1234, 2341, 3412, 4123]:\n",
        "  output_dir = f\"./output/tiny{task_name}-bt-{seed}\"\n",
        "  do_target_task_finetuning(\n",
        "      seed=seed,\n",
        "      model_name_or_path=model_name_or_path,\n",
        "      task_name=f\"{task_name}-2\",\n",
        "      task_type=\"text_classification\",\n",
        "      do_train=True,\n",
        "      do_eval=False, \n",
        "      do_lower_case=True,\n",
        "      data_dir=data_dir,\n",
        "      max_seq_length=128,\n",
        "      per_device_train_batch_size=32,\n",
        "      learning_rate=2e-5,\n",
        "      num_train_epochs=3.0,\n",
        "      model_cache_dir=model_cache_dir,\n",
        "      data_cache_dir=data_cache_dir,\n",
        "      output_dir=output_dir,\n",
        "      overwrite_output_dir=True\n",
        "  )\n",
        "\n",
        "# Evaluate BERT on the dev set\n",
        "results = []\n",
        "for seed in [1234, 2341, 3412, 4123]:\n",
        "  model_dir = f\"./output/tiny{task_name}-bt-{seed}\"\n",
        "  result = do_target_task_finetuning(\n",
        "      seed=seed,\n",
        "      model_name_or_path=model_dir,\n",
        "      task_name=f\"{task_name}-2\",\n",
        "      task_type=\"text_classification\",\n",
        "      do_train=False,\n",
        "      do_eval=True, \n",
        "      do_lower_case=True,\n",
        "      data_dir=data_dir,\n",
        "      max_seq_length=128,\n",
        "      model_cache_dir=model_cache_dir,\n",
        "      data_cache_dir=data_cache_dir,\n",
        "      output_dir=model_dir,\n",
        "  )\n",
        "  results.append(result[\"eval_acc\"])\n",
        "\n",
        "results = np.array(results)\n",
        "mean = np.mean(results)\n",
        "std = np.std(results)\n",
        "\n",
        "print(\"===== Data augmentation using back-translation =====\")\n",
        "print(f\"Performance when fine-tuning BERT: {mean} +/- {std}\")\n",
        "elapsed_time = timeit.default_timer() - start_time\n",
        "print(f\"Time elapsed: {elapsed_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t10LtOVEn4u0"
      },
      "source": [
        " ### Question 3.6 (5 points)\n",
        "Briefly explain your backtranslation strategy here. Why do you think it resulted in an improvement?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HbdYOUZ-xUn"
      },
      "source": [
        "### Answer:\n",
        "\n",
        "Adding pivot languages for data augmentation includes different paraphrases of the original text keeping the semantic meaning similar to the original English sentence. By doing back-translation we are effectively increasing the dataset size and are able to train a better model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SgNZTjrhcHa0"
      ],
      "name": "CS685 Fall 2021: Extra credit assignment_Nalini.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03fd0f50f6a248d5866cd28ab855ccb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_99540568054046e1b974682e4d83132d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_46f27ea44c2d4e658953b516aa2c5570",
              "IPY_MODEL_356ac7c279f64ed3a3bda5b6e33b0fd4",
              "IPY_MODEL_489892ceabfc40d1b1a8a666bd92c845"
            ]
          }
        },
        "99540568054046e1b974682e4d83132d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46f27ea44c2d4e658953b516aa2c5570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fde2f360c4444165ac493fbf62f05104",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b217f2c0bf34849b5d01de8272eeefd"
          }
        },
        "356ac7c279f64ed3a3bda5b6e33b0fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_99fd0eb9d4c04bed991b8d7bc5fa6665",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e10c03f2293e41a489edd64f14561532"
          }
        },
        "489892ceabfc40d1b1a8a666bd92c845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_56ff232aa8414bc3a9eec5a862802fd5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 14.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8203f8e7a624e7193c9bd9b65df000f"
          }
        },
        "fde2f360c4444165ac493fbf62f05104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b217f2c0bf34849b5d01de8272eeefd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99fd0eb9d4c04bed991b8d7bc5fa6665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e10c03f2293e41a489edd64f14561532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56ff232aa8414bc3a9eec5a862802fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8203f8e7a624e7193c9bd9b65df000f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20b4f132421d4f2c84aecb06ad21cd85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e8728e835bc4419abe1d0dbc9881c23e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e5085e3d63ab443a9fdf39c105268f5d",
              "IPY_MODEL_4977fdf620f640dcbe94fdd9054729d6",
              "IPY_MODEL_dd403224f5fe4350b6718a2cd48d7cec"
            ]
          }
        },
        "e8728e835bc4419abe1d0dbc9881c23e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5085e3d63ab443a9fdf39c105268f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_847a1734180e43b39e1891c035a2eac7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a5749b541004ea09c7a5212373bb4d9"
          }
        },
        "4977fdf620f640dcbe94fdd9054729d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_55a84f7205af4814abcb55c70ddf9d37",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_597c6a43cfd14053bfdcb26f60737912"
          }
        },
        "dd403224f5fe4350b6718a2cd48d7cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8012872917144e284fdc4135257113d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 556kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_efe7a0c1cee542c69510e984460786ea"
          }
        },
        "847a1734180e43b39e1891c035a2eac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a5749b541004ea09c7a5212373bb4d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55a84f7205af4814abcb55c70ddf9d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "597c6a43cfd14053bfdcb26f60737912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8012872917144e284fdc4135257113d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "efe7a0c1cee542c69510e984460786ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42972fe9e61945419b2872afbd7c77f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c27247aa26a841639c38c9467f0a9dac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a3c13c5bf34f42768ebb214e1bf5470d",
              "IPY_MODEL_c1942c0fa18944ce82287b333bf4e83c",
              "IPY_MODEL_620b8c418d4d417fbf03e28428c30694"
            ]
          }
        },
        "c27247aa26a841639c38c9467f0a9dac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3c13c5bf34f42768ebb214e1bf5470d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dbe76ef29f3d48faab041b7979022781",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e214979a15ad40429441198ae1a6d42d"
          }
        },
        "c1942c0fa18944ce82287b333bf4e83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c86049a8c924001abab2a3629aae62c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d09ef5106a0a40b786a203274fa105d8"
          }
        },
        "620b8c418d4d417fbf03e28428c30694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f442026b56af46a78a135293da2cafd6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:07&lt;00:00, 57.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3871ecd93dd34457829d9eec7bfc03f0"
          }
        },
        "dbe76ef29f3d48faab041b7979022781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e214979a15ad40429441198ae1a6d42d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c86049a8c924001abab2a3629aae62c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d09ef5106a0a40b786a203274fa105d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f442026b56af46a78a135293da2cafd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3871ecd93dd34457829d9eec7bfc03f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}